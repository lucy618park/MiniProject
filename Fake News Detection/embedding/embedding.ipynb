{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_iPEzyhVf-VF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "hhjJI33Fj__9",
    "outputId": "95ccf46e-080a-4721-aaa1-07ccbcc8264c"
   },
   "outputs": [],
   "source": [
    "# FastText 모델 학습\n",
    "def train_fasttext_model(combined_data):\n",
    "    # FastText 모델 학습\n",
    "    model = FastText(sentences=[sentence.split() for sentence in combined_data],  # 데이터를 단어별로 분리하여 학습\n",
    "                     vector_size=150,  # 단어 벡터의 차원 크기\n",
    "                     window=7,         # 주변 단어의 범위\n",
    "                     sg=1,             # 1은 skip-gram 방식, 0은 CBOW 방식\n",
    "                     negative=3,       # negative sampling 수\n",
    "                     min_count=5,      # 최소 등장 횟수\n",
    "                     epochs=10)        # 학습 반복 횟수\n",
    "    model.save('fasttext.model')  # 모델 저장\n",
    "    return model\n",
    "\n",
    "# 벡터화 함수 정의\n",
    "def vectorize_text(text, model):\n",
    "    # 텍스트를 토큰화하고 각 단어의 벡터 평균을 구함\n",
    "    tokens = text.split()\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)  # 각 단어 벡터의 평균 반환\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # 빈 텍스트의 경우 0 벡터 반환\n",
    "\n",
    "# 데이터 로드 및 벡터화 후 덮어쓰기\n",
    "def embedding(filename):\n",
    "    # CSV 파일 로드\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # 뉴스 제목과 내용 결합하여 학습용 데이터 준비\n",
    "    combined_data = df['newsTitle'].fillna('') + \" \" + df['newsContent'].fillna('')\n",
    "\n",
    "    # FastText 모델 학습\n",
    "    model = train_fasttext_model(combined_data)\n",
    "\n",
    "    # 벡터화 및 원래 데이터 덮어쓰기\n",
    "    for index, row in df.iterrows():\n",
    "        if 'newsTitle' in row and pd.notna(row['newsTitle']):\n",
    "            df.at[index, 'newsTitle'] = vectorize_text(row['newsTitle'], model).tolist()\n",
    "        if 'newsContent' in row and pd.notna(row['newsContent']):\n",
    "            df.at[index, 'newsContent'] = vectorize_text(row['newsContent'], model).tolist()\n",
    "\n",
    "    # 새로운 파일 경로로 저장\n",
    "    new_filename = \"embedded_\" + filename\n",
    "    df.to_csv(new_filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 후 CSV 저장\n",
    "embedding('newsdata_train.csv')\n",
    "embedding('newsdata_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xN5FBiNvm8yR",
    "outputId": "308f9f62-9269-49a6-f4cf-13e24621ef8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25104544 -0.07970234 -0.02213505  0.17463736  0.30319142  0.14689553\n",
      "  0.12875228  0.02686078 -0.49554014  0.18140385  0.21220806 -0.13649045\n",
      " -0.17695391  0.02300723  0.18467507  0.1247035   0.17377234 -0.3212884\n",
      "  0.16452423 -0.42488682  0.399189   -0.07933641  0.12229703 -0.03248195\n",
      " -0.06627069  0.1810525  -0.06949529 -0.15336135 -0.01214663  0.49436295\n",
      "  0.08129417  0.04610986  0.24088158  0.14088747  0.18017589  0.52900684\n",
      "  0.0963407   0.0335203  -0.34491783  0.07212323  0.05752467 -0.3886918\n",
      "  0.06200375  0.04256329  0.30373427  0.5870484  -0.22144698  0.49868852\n",
      " -0.3228535   0.06863975  0.10747646  0.04319504  0.03697788  0.19020906\n",
      " -0.5343235  -0.11278027  0.05165378  0.1289041  -0.14015892 -0.19388796\n",
      " -0.16653273 -0.07024307 -0.33946943  0.0016133   0.2699325  -0.42199978\n",
      " -0.01871256  0.55657935 -0.3300532  -0.05064172 -0.39031273 -0.08447891\n",
      " -0.00993035  0.0453406   0.25731307  0.19328137 -0.1725997  -0.18256144\n",
      " -0.41430107  0.13684863  0.16288933 -0.29569685  0.33836848  0.22600561\n",
      "  0.1570918  -0.32691234  0.12477972 -0.06834229 -0.04032785  0.26349583\n",
      "  0.47317034  0.27622655 -0.10920607 -0.05031952  0.6986703   0.12031657\n",
      " -0.13918103  0.21428198 -0.18406951  0.04266937]\n",
      "[('서대문', 0.7177121639251709), ('강남구', 0.6943551301956177), ('광진', 0.6909937858581543), ('노원', 0.6830289363861084), ('서초구', 0.6763381958007812), ('송파', 0.6680499911308289), ('서대문구', 0.667640209197998), ('노원구', 0.6591001152992249), ('서초동', 0.6495409607887268), ('남대문', 0.6325822472572327)]\n"
     ]
    }
   ],
   "source": [
    "model = FastText.load('fasttext.model')\n",
    "print(model.wv['서울'])\n",
    "print(model.wv.most_similar('서울'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
